---
id: structured-outputs
title: Sa√≠das Estruturadas
---

# Sa√≠das estruturadas

Sa√≠das Estruturadas garantem que os dados gerados pelos modelos sigam esquemas predefinidos fornecidos pelo usu√°rio, como JSON, simplificando integra√ß√µes em aplica√ß√µes. Quando o formato da resposta √© cr√≠tico, estrat√©gias como express√µes regulares (regex) podem ser usadas, mas essas abordagens s√£o frequentemente fr√°geis, complexas e incapazes de garantir que todos os campos sejam extra√≠dos de forma precisa e consistente. Por outro lado, Sa√≠das Estruturadas oferecem uma solu√ß√£o mais confi√°vel, reduzindo erros e facilitando a integra√ß√£o direta. Contudo, para casos em que respostas narrativas ou flexibilidade s√£o priorit√°rias, seu uso n√£o √© necess√°rio.

## Exemplos de Uso

### 1. Extra√ß√£o de Dados

Extraia informa√ß√µes estruturadas de textos n√£o estruturados:

```python
from pydantic import BaseModel
import openai

client = openai.OpenAI(
    api_key="" #Sua API_KEY
    base_url="https://chat.maritaca.ai/api",
)

class DetalhesEvento(BaseModel):
    nome_evento: str
    data: str
    participantes: list[str]
    traje: list[str]

completion = client.beta.chat.completions.parse(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "Extraia detalhes do evento."},
        {"role": "user", "content": "Jo√£o e Maria v√£o a uma festa junina no s√°bado, √†s 18h, em Campina Grande. Eles v√£o vestidos a car√°ter: Maria com um vestido florido e Jo√£o com camisa xadrez e chap√©u de palha."},
    ],
    response_format=DetalhesEvento,
)

evento = completion.choices[0].message.parsed

print(evento)
```

### 2. An√°lise de Sentimentos

Identifique sentimentos em textos:

```python
import openai

client = openai.OpenAI(
    api_key="" #Sua API_KEY,
    base_url="https://chat.maritaca.ai/api",
)

sentimento_schema = {
    "type": "object",
    "properties": {
        "texto": {"type": "string"},
        "sentimento": {"type": "string", "enum": ["positivo", "negativo", "neutro"]},
    },
    "required": ["texto", "sentimento"],
}

completion = client.beta.chat.completions.create(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "Classifique o sentimento do texto em positivo, negativo ou neutro."},
        {"role": "user", "content": "Estou muito feliz com o servi√ßo oferecido!"},
    ],
    response_format={"type": "json_schema", "json_schema": sentimento_schema}
)

resultado = completion.choices[0].message["content"]
print(resultado)
```

### 3. Plano de Leitura

Gere um plano de leitura estruturado com base na solicita√ß√£o do usu√°rio, validando os dados com um esquema JSON e exibindo os livros com seus detalhes.

```python
from enum import Enum
from typing import List, Optional
from pydantic import BaseModel
import openai
import json

client = openai.OpenAI(
    api_key="",  #Sua API_KEY
    base_url="https://chat.maritaca.ai/api",
)

class TipoLeitura(str, Enum):
    classico = "cl√°ssico"
    contemporaneo = "contempor√¢neo"

class Livro(BaseModel):
    tipo: TipoLeitura
    titulo: str
    autor: str
    descricao: str

Livro.model_rebuild() 

class PlanoLeitura(BaseModel):
    nome_plano: str
    livros: List[Livro]


schema={
          "type": "object",
          "properties": {
              "nome_plano": {"type": "string"},
              "livros": {
                  "type": "array",
                  "items": {
                      "type": "object",
                      "properties": {
                          "tipo": {"type": "string", "enum": ["cl√°ssico", "contempor√¢neo"]},
                          "titulo": {"type": "string"},
                          "autor": {"type": "string"},
                          "descricao": {"type": "string"},
                          "subitens": {"type": ["array", "null"]}
                      },
                      "required": ["tipo", "titulo", "autor", "descricao"]
                  }
              }
          },
          "required": ["nome_plano", "livros"]
        }

completion = client.beta.chat.completions.parse(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "Voc√™ √© um gerador de planos de leitura. Converta a solicita√ß√£o do usu√°rio em um plano de leitura estruturado."},
        {"role": "user", "content": "Crie um plano de leitura para explorar a literatura brasileira, incluindo cl√°ssicos e literatura contempor√¢nea."}
    ],
    response_format={"type": "json_schema", "json_schema": schema}
)

plano_leitura = PlanoLeitura.model_validate(json.loads(completion.choices[0].message.content))

print("Nome do Plano:", plano_leitura.nome_plano)
print("Livros:")
for livro in plano_leitura.livros:
    print(f" - {livro.titulo} por {livro.autor}: {livro.descricao}")

```


### 4. Uso com stream

No caso de uso com stream, as sa√≠das estruturadas podem ser processadas em tempo real, conforme s√£o geradas, proporcionando uma experi√™ncia mais interativa. Esse m√©todo √© particularmente vantajoso para lidar com tarefas que envolvem a gera√ß√£o de grandes volumes de dados ou respostas extensas. A seguir, apresentamos um exemplo:

```python
from typing import List, Dict
from pydantic import BaseModel
import openai

class PratosTipicosModel(BaseModel):
    pratos: List[str]

client = openai.OpenAI(
    api_key="",   #Sua API_KEY
    base_url="https://chat.maritaca.ai/api",
)

with client.beta.chat.completions.stream(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "Identifique os pratos t√≠picos brasileiros no texto fornecido."},
        {
            "role": "user",
            "content": "Na festa junina, temos canjica, pamonha, curau e quent√£o, al√©m de muita m√∫sica e dan√ßa.",
        },
    ],
    response_format=PratosTipicosModel,
) as stream:
    for event in stream:
        if event.type == "content.delta":
            if event.parsed is not None:
                print("content.delta parsed:", event.parsed)
        elif event.type == "content.done":
            print("content.done")
        elif event.type == "error":
            print("Error in stream:", event.error)

final_completion = stream.get_final_completion()
print("Final completion:", final_completion)


```

## Como usar o par√¢metro response_format
O par√¢metro `response_format` √© usado para instruir que as respostas geradas pelo modelo sigam um formato estruturado predefinido. Os valores para o response_format s√£o:
1. Schema JSON (json_schema): Defina um esquema JSON para validar a estrutura e os tipos de dados da resposta.
```python
response_format={ type: "json_schema", json_schema: {"strict": true, "schema": ...} }
ou
response_format={ type: "json_schema", schema: {...} }
```
2. Modelos Pydantic: Utilize classes Pydantic para mapear e validar os dados retornados.
```python
response_format=ModelPydantic
```
3. Objeto JSON simples tamb√©m conhecido por modo json onde √© solicitado um objeto json sem valida√ß√µes adicionais: 
```python
response_format={"type": "json_object"}
```

## Boas Pr√°ticas

* Defina Esquemas Claros: Use ferramentas como JSON Schema ou Pydantic para projetar esquemas adequados.
* Valide a Entrada: Certifique-se de que as entradas dos usu√°rios sejam compat√≠veis com o esquema.
* Manuseio de Erros: Inclua l√≥gica para tratar recusas ou respostas malformadas programaticamente.

<br/>
<div className="custom-box" style={{
    display: 'flex', 
    alignItems: 'center', 
    backgroundColor: '#B0E0E6', 
    padding: '10px', 
    border: '1px solid #B0E0E6', 
    borderRadius: '5px', 
    margin: '10px 0',
    color: 'black'
    }}>
    <span style={{ fontSize: '1.5em', marginRight: '10px', color: '#B0E0E6' }}>üí°</span>
    <div>
        <strong style={{ display: 'block', fontSize: '1em', marginBottom: '5px' }}> MODO JSON </strong>
        <p style={{ fontSize: '0.9em' }}> O modo JSON apenas garante que a sa√≠da do modelo seja JSON v√°lido. J√° o Structured Outputs corresponde de forma confi√°vel √† sa√≠da do modelo ao esquema que voc√™ especificar. Recomendamos que voc√™ use o Structured Outputs se ele for suportado para o seu caso de uso. Ao usar o modo JSON, caso a instru√ß√£o de produzir um JSON n√£o seja explicitamente passada para o modelo, este pode gerar um fluxo intermin√°vel de espa√ßos em branco, e a solicita√ß√£o pode ser executada continuamente at√© atingir o limite de tokens. </p>
    </div>
</div>
<br/>