---
id: openai-compatibilidade
title: Compatibilidade com a OpenAI
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Compatibilidade com a OpenAI 

A Maritaca API √© compat√≠vel com as bibliotecas de clientes da OpenAI, tornando f√°cil experimentar nossos modelos de c√≥digo aberto em aplica√ß√µes existentes.

Isso significa que os modelos Sabi√° podem ser utilizados em qualquer programa que use as bibliotecas da OpenAI.

### **Configurando a OpenAI para usar a Maritaca API**

#### Intala√ß√£o da biblioteca

Primeiro instale a biblioteca da openai digitando este comando no terminal: 

```bash
pip install openai
```

### üõ†Ô∏è Configurando o Cliente
A configura√ß√£o do cliente OpenAI √© o primeiro passo para utilizar a API. Certifique-se de fornecer sua chave de API e a URL base personalizada. Ou seja, para utilizar a Maritaca API, basta apontar o endpoint para `https://chat.maritaca.ai/api`, preencher a chave de API com uma chave obtida na plataforma (como descrito em in√≠cio r√°pido) e usar um dos modelos Sabi√°.
```python
import os
import openai

client = openai.OpenAI(
    api_key=os.environ.get("MARITACA_API_KEY"),
    base_url="https://chat.maritaca.ai/api",
)
```


### üó®Ô∏è Realizando uma Requisi√ß√£o de Chat

Voc√™ pode fazer uma requisi√ß√£o de chat para o modelo sabia-3 passando uma lista de mensagens.

<Tabs>
<TabItem value="python" label="Python" default>
```python
response = client.chat.completions.create(
  model="sabia-3",
  messages=[
    {"role": "system", "content": "Voc√™ √© um agente de viagem. Seja descritivo e gentil."},
    {"role": "user", "content": "Me fale sobre o Cristo Redentor"},
  ],
  max_tokens=50
)

print(response.choices[0].message.content)
```
</TabItem>
<TabItem value="curl" label="cURL">
```bash
curl https://chat.maritaca.ai/api/chat/completions \
  -H "Authorization: Bearer minha_chave" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "sabia-3",
    "messages": [{"role": "system", "content": "Voc√™ √© um agente de viagem. Seja descritivo e gentil."},
                 {"role": "user", "content": "Me fale sobre o Cristo Redentor"}],
    "max_tokens": 50
  }'
```
</TabItem>
</Tabs>

### üíª Realizando uma requisi√ß√£o para completar entrada
Al√©m de chats, voc√™ tamb√©m pode utilizar o modelo para completar a entrada, como no exemplo abaixo:

<Tabs>
<TabItem value="python" label="Python" default>
```python
response = client.completions.create(
  model="sabia-3",
  prompt="Era uma vez, em um reino distante, um jovem aventureiro que sonhava em explorar terras desconhecidas. Um dia, ele encontrou um mapa misterioso que mostrava o caminho para um tesouro perdido",
  max_tokens=175
)

print(response.choices[0].text)
```
</TabItem>
<TabItem value="curl" label="cURL">
```bash
curl https://chat.maritaca.ai/api/completions \
  -H "Authorization: Bearer minha_chave" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "sabia-3",
    "prompt": "def menu_principal():\n  print(\"Bem-vindo ao Receitas Brasileiras!\")\n  print(\"Escolha uma das op√ß√µes abaixo para ver a receita:\")\n  print(\"1. Feijoada\")",
    "max_tokens": 175
  }'
```
</TabItem>
</Tabs>

### üîÑ Requisi√ß√£o de Chat com Streaming

Para receber as respostas em tempo real (streaming), voc√™ pode utilizar o par√¢metro stream=True.

<Tabs>
<TabItem value="python" label="Python" default>
```python
import os
import openai

stream = client.chat.completions.create(
  model="sabia-3",
  messages=[
    {"role": "system", "content": "Voc√™ √© um agente de viagem. Seja descritivo e gentil."},
    {"role": "user", "content": "Me fale sobre o Cristo Redentor"},
  ],
  stream=True,
  max_tokens=50
)
for chunk in stream:
  print(chunk.choices[0].delta.content or "", end="", flush=True)
```
</TabItem>
<TabItem value="curl" label="cURL">
```bash
curl https://chat.maritaca.ai/api/chat/completions \
  -H "Authorization: Bearer minha_chave" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "sabia-3",
    "messages": [{"role": "system", "content": "Voc√™ √© um agente de viagem. Seja descritivo e gentil."},
                 {"role": "user", "content": "Me fale sobre o Cristo Redentor"}],
    "max_tokens": 50
  }'
```
</TabItem>
</Tabs>
