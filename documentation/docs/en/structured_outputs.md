---
id: structured-outputs
title: Structured Outputs
---

# Structured Outputs

Structured Outputs ensure that the data generated by models adheres to predefined user-provided schemas, such as JSON, simplifying integrations into applications. When the response format is critical, strategies like regular expressions (regex) can be employed, but these approaches are often fragile, complex, and unable to guarantee that all fields are extracted accurately and consistently. On the other hand, Structured Outputs offer a more reliable solution, reducing errors and facilitating direct integration. However, in cases where narrative responses or flexibility are a priority, their use is not necessary.

## Use Cases Examples

### 1. Data Extraction

Extract structured information from unstructured text:

```python
from pydantic import BaseModel
import openai

client = openai.OpenAI(
    api_key="", #Your API_KEY
    base_url="https://chat.maritaca.ai/api",
)

class EventDetails(BaseModel):
    event_name: str
    date: str
    participants: list[str]
    attire: list[str]

completion = client.beta.chat.completions.parse(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "Extract event details."},
        {"role": "user", "content": "Jo√£o and Maria are going to a June festival on Saturday at 6 PM in Campina Grande. They will be dressed for the occasion: Maria in a floral dress and Jo√£o in a plaid shirt and straw hat."}
    ],
    response_format=EventDetails,
)

event_response = completion.choices[0].message.parsed

print(event_response)
```

### 2. Sentiment Analysis

Identify sentiments in texts:

```python
import openai

client = openai.OpenAI(
    api_key="", #Your API_KEY
    base_url="https://chat.maritaca.ai/api",
)

sentiment_schema = {
    "type": "object",
    "properties": {
        "text": {"type": "string"},
        "sentiment": {"type": "string", "enum": ["positive", "negative", "neutral"]},
    },
    "required": ["text", "sentiment"],
}

completion = client.beta.chat.completions.create(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "Classify the sentiment of the text as positive, negative, or neutral."},
        {"role": "user", "content": "I am very happy with the service provided!"},
    ],
    response_format={"type": "json_schema", "json_schema": sentiment_schema}
)

result = completion.choices[0].message["content"]
print(result)

```

### 3. Reading Plan

Generate a structured reading plan based on the user's request, validating the data with a JSON schema and displaying the books with their details.

```python
from enum import Enum
from typing import List, Optional
from pydantic import BaseModel
import openai
import json

client = openai.OpenAI(
    api_key="",  #Your API_KEY
    base_url="https://chat.maritaca.ai/api",
)

class ReadingType(str, Enum):
    classic = "classic"
    contemporary = "contemporary"

class Book(BaseModel):
    type: ReadingType
    title: str
    author: str
    description: str

Book.model_rebuild()

class ReadingPlan(BaseModel):
    plan_name: str
    books: List[Book]


schema = {
    "type": "object",
    "properties": {
        "plan_name": {"type": "string"},
        "books": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "type": {"type": "string", "enum": ["classic", "contemporary"]},
                    "title": {"type": "string"},
                    "author": {"type": "string"},
                    "description": {"type": "string"},
                    "subitems": {"type": ["array", "null"]}
                },
                "required": ["type", "title", "author", "description"]
            }
        }
    },
    "required": ["plan_name", "books"]
}

completion = client.beta.chat.completions.parse(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "You are a reading plan generator. Convert the user's request into a structured reading plan."},
        {"role": "user", "content": "Create a reading plan to explore Brazilian literature, including classics and contemporary works."}
    ],
    response_format={"type": "json_schema", "json_schema": schema}
)

reading_plan = ReadingPlan.model_validate(json.loads(completion.choices[0].message.content))

print("Plan Name:", reading_plan.plan_name)
print("Books:")
for book in reading_plan.books:
    print(f" - {book.title} by {book.author}: {book.description}")


```


### 4. Usage with Stream

In the case of stream usage, structured outputs can be processed in real time as they are generated, providing a more interactive experience. This method is particularly advantageous for handling tasks involving the generation of large volumes of data or extensive responses. Below, we present an example:

```python
from typing import List, Dict
from pydantic import BaseModel
import openai

class TypicalDishesModel(BaseModel):
    dishes: List[str]

client = openai.OpenAI(
    api_key="",  #Your API_KEY
    base_url="https://chat.maritaca.ai/api",
)

with client.beta.chat.completions.stream(
    model="sabia-3",
    messages=[
        {"role": "system", "content": "Identify the typical Brazilian dishes in the provided text."},
        {
            "role": "user",
            "content": "At the June festival, we have canjica, pamonha, curau, and quent√£o, along with lots of music and dancing.",
        },
    ],
    response_format=TypicalDishesModel,
) as stream:
    for event in stream:
        if event.type == "content.delta":
            if event.parsed is not None:
                print("content.delta parsed:", event.parsed)
        elif event.type == "content.done":
            print("content.done")
        elif event.type == "error":
            print("Error in stream:", event.error)

final_completion = stream.get_final_completion()
print("Final completion:", final_completion)


```

## How to Use the response_format Parameter

The `response_format` parameter is used to instruct the model to generate responses that follow a predefined structured format. The values for response_format are:

1. JSON Schema (json_schema): Define a JSON schema to validate the structure and data types of the response.

```python
response_format={type: "json_schema", json_schema: {"strict": true, "schema": ...}}
or
response_format={type: "json_schema", schema: {...}}

```
2. Pydantic Models: Use Pydantic classes to map and validate the returned data.
```python
response_format=ModelPydantic
```
3. Simple JSON Object: Also known as json mode, where a JSON object is requested without additional validations:
```python
response_format={"type": "json_object"}
```

## Best Practices

* Define Clear Schemas: Use tools like JSON Schema or Pydantic to design appropriate schemas.
* Validate Input: Ensure that user inputs are compatible with the schema.
* Error Handling: Include logic to handle refusals or malformed responses programmatically.

<br/>
<div className="custom-box" style={{
    display: 'flex', 
    alignItems: 'center', 
    backgroundColor: '#B0E0E6', 
    padding: '10px', 
    border: '1px solid #B0E0E6', 
    borderRadius: '5px', 
    margin: '10px 0',
    color: 'black'
    }}>
    <span style={{ fontSize: '1.5em', marginRight: '10px', color: '#B0E0E6' }}>üí°</span>
    <div>
        <strong style={{ display: 'block', fontSize: '1em', marginBottom: '5px' }}> JSON MODE </strong>
        <p style={{ fontSize: '0.9em' }}> The JSON mode only ensures that the model's output is valid JSON. Structured Outputs, on the other hand, reliably match the model's output to the schema you specify. We recommend using Structured Outputs if it is supported for your use case. When using JSON mode, if the instruction to produce a JSON object is not explicitly passed to the model, it may generate an endless stream of whitespace, and the request could run continuously until it reaches the token limit.</p>
    </div>
</div>
<br/>