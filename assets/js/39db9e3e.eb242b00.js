"use strict";(self.webpackChunkmaritaca=self.webpackChunkmaritaca||[]).push([[7415],{743:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>m,frontMatter:()=>i,metadata:()=>c,toc:()=>u});var s=a(4848),t=a(8453),o=a(1470),r=a(9365);const i={id:"responses-api",title:"Responses API"},l="Responses API",c={id:"pt/responses-api",title:"Responses API",description:"A Responses API \xe9 a interface principal para interagir com os modelos Sabi\xe1. Ela oferece uma superf\xedcie \xfanica e coesa para gerar texto, chamar fun\xe7\xf5es externas, produzir sa\xeddas estruturadas e construir fluxos de conversa multi-turno \u2014 tudo atrav\xe9s de um \xfanico endpoint.",source:"@site/docs/pt/responses-api.md",sourceDirName:"pt",slug:"/pt/responses-api",permalink:"/pt/responses-api",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"responses-api",title:"Responses API"},sidebar:"sidebarPt",previous:{title:"Compatibilidade com a OpenAI",permalink:"/pt/api/openai-compatibilidade"},next:{title:"Chamada de fun\xe7\xf5es",permalink:"/pt/chamada-funcao"}},d={},u=[{value:"Responses API vs. Chat Completions API",id:"responses-api-vs-chat-completions-api",level:3},{value:"Migrando da Chat Completions",id:"migrando-da-chat-completions",level:3},{value:"In\xedcio r\xe1pido",id:"in\xedcio-r\xe1pido",level:2},{value:"Formatos de entrada",id:"formatos-de-entrada",level:2},{value:"Texto simples \u2014 para perguntas diretas",id:"texto-simples--para-perguntas-diretas",level:3},{value:"Lista de mensagens \u2014 para conversas e contexto",id:"lista-de-mensagens--para-conversas-e-contexto",level:3},{value:"Com instru\xe7\xf5es de sistema",id:"com-instru\xe7\xf5es-de-sistema",level:3},{value:"Streaming (resposta em tempo real)",id:"streaming-resposta-em-tempo-real",level:2},{value:"Mais exemplos",id:"mais-exemplos",level:2},{value:"Exemplo 1 \u2014 Chamada de fun\xe7\xf5es (fluxo completo)",id:"exemplo-1--chamada-de-fun\xe7\xf5es-fluxo-completo",level:3},{value:"Exemplo 2 \u2014 Sa\xeddas estruturadas com Pydantic",id:"exemplo-2--sa\xeddas-estruturadas-com-pydantic",level:3},{value:"Exemplo 3 \u2014 Streaming com tracking de tokens",id:"exemplo-3--streaming-com-tracking-de-tokens",level:3},{value:"Exemplo 4 \u2014 Chatbot multi-turno com mem\xf3ria",id:"exemplo-4--chatbot-multi-turno-com-mem\xf3ria",level:3}];function p(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"responses-api",children:"Responses API"})}),"\n",(0,s.jsx)(n.p,{children:"A Responses API \xe9 a interface principal para interagir com os modelos Sabi\xe1. Ela oferece uma superf\xedcie \xfanica e coesa para gerar texto, chamar fun\xe7\xf5es externas, produzir sa\xeddas estruturadas e construir fluxos de conversa multi-turno \u2014 tudo atrav\xe9s de um \xfanico endpoint."}),"\n",(0,s.jsx)(n.p,{children:"Se voc\xea j\xe1 utiliza a Chat Completions API, a Responses API \xe9 sua evolu\xe7\xe3o natural: mesma compatibilidade com o SDK da OpenAI, mas com uma interface mais expressiva e recursos adicionais que simplificam integra\xe7\xf5es complexas."}),"\n",(0,s.jsx)(n.h3,{id:"responses-api-vs-chat-completions-api",children:"Responses API vs. Chat Completions API"}),"\n",(0,s.jsx)(n.p,{children:"A Responses API substitui a Chat Completions como a interface recomendada para novos projetos. A tabela abaixo resume as diferen\xe7as:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Aspecto"}),(0,s.jsx)(n.th,{children:"Chat Completions"}),(0,s.jsx)(n.th,{children:"Responses API"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Endpoint"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"POST /v1/chat/completions"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"POST /v1/responses"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Entrada"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"messages"})," (lista de mensagens)"]}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"input"})," (string ou lista de itens)"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Instru\xe7\xf5es de sistema"}),(0,s.jsxs)(n.td,{children:["Via mensagem com ",(0,s.jsx)(n.code,{children:'role: "system"'})]}),(0,s.jsxs)(n.td,{children:["Par\xe2metro dedicado ",(0,s.jsx)(n.code,{children:"instructions"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Sa\xedda"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"choices[0].message.content"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"output[0].content[0].text"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Streaming"}),(0,s.jsxs)(n.td,{children:["(",(0,s.jsx)(n.code,{children:"chat.completion.chunk"}),")"]}),(0,s.jsxs)(n.td,{children:["(",(0,s.jsx)(n.code,{children:"response.output_text.delta"}),", ",(0,s.jsx)(n.code,{children:"response.completed"}),", etc.)"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Chamada de fun\xe7\xf5es"}),(0,s.jsxs)(n.td,{children:["Via ",(0,s.jsx)(n.code,{children:"tool_calls"})," no message"]}),(0,s.jsxs)(n.td,{children:["Itens tipados ",(0,s.jsx)(n.code,{children:"function_call"})," no output"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Sa\xeddas estruturadas"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"response_format"})}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"text.format"})," com ",(0,s.jsx)(n.code,{children:"json_schema"})]})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"A Chat Completions API continua dispon\xedvel e funcional. Se voc\xea j\xe1 tem uma integra\xe7\xe3o funcionando com ela, n\xe3o h\xe1 necessidade imediata de migrar. Para novos projetos, recomendamos a Responses API."}),"\n",(0,s.jsx)(n.h3,{id:"migrando-da-chat-completions",children:"Migrando da Chat Completions"}),"\n",(0,s.jsx)(n.p,{children:"A migra\xe7\xe3o \xe9 direta. Compare os dois exemplos equivalentes:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Chat Completions:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'response = client.chat.completions.create(\n    model="sabia-4",\n    messages=[\n        {"role": "system", "content": "Responda de forma concisa."},\n        {"role": "user", "content": "Qual \xe9 a capital do Brasil?"},\n    ],\n    max_tokens=200,\n)\nprint(response.choices[0].message.content)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Responses API:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'response = client.responses.create(\n    model="sabia-4",\n    instructions="Responda de forma concisa.",\n    input="Qual \xe9 a capital do Brasil?",\n    max_output_tokens=200,\n)\nprint(response.output[0].content[0].text)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["As principais mudan\xe7as s\xe3o: ",(0,s.jsx)(n.code,{children:"messages"})," vira ",(0,s.jsx)(n.code,{children:"input"}),", a mensagem ",(0,s.jsx)(n.code,{children:"system"})," vira o par\xe2metro ",(0,s.jsx)(n.code,{children:"instructions"}),", ",(0,s.jsx)(n.code,{children:"max_tokens"})," vira ",(0,s.jsx)(n.code,{children:"max_output_tokens"}),", e o acesso \xe0 resposta muda de ",(0,s.jsx)(n.code,{children:"choices[0].message.content"})," para ",(0,s.jsx)(n.code,{children:"output[0].content[0].text"}),"."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"in\xedcio-r\xe1pido",children:"In\xedcio r\xe1pido"}),"\n",(0,s.jsx)(n.p,{children:"Instale a biblioteca da OpenAI (a Maritaca API \xe9 compat\xedvel com o SDK da OpenAI):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install openai\n"})}),"\n",(0,s.jsx)(n.p,{children:"Fa\xe7a sua primeira requisi\xe7\xe3o:"}),"\n",(0,s.jsxs)(o.A,{children:[(0,s.jsx)(r.A,{value:"python",label:"Python",default:!0,children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import openai\n\nclient = openai.OpenAI(\n    api_key="SUA_CHAVE_API",\n    base_url="https://chat.maritaca.ai/api",\n)\n\nresponse = client.responses.create(\n    model="sabia-4",\n    input="Qual \xe9 a capital do Brasil?",\n)\n\nprint(response.output[0].content[0].text)\n# "A capital do Brasil \xe9 Bras\xedlia."\n'})})}),(0,s.jsx)(r.A,{value:"curl",label:"cURL",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST https://chat.maritaca.ai/api/v1/responses \\\n  -H "Authorization: Bearer SUA_CHAVE_API" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "sabia-4",\n    "input": "Qual \xe9 a capital do Brasil?"\n  }\'\n'})})})]}),"\n",(0,s.jsx)(n.h2,{id:"formatos-de-entrada",children:"Formatos de entrada"}),"\n",(0,s.jsxs)(n.p,{children:["O par\xe2metro ",(0,s.jsx)(n.code,{children:"input"})," aceita dois formatos. Escolha o que melhor se adequa ao seu caso:"]}),"\n",(0,s.jsx)(n.h3,{id:"texto-simples--para-perguntas-diretas",children:"Texto simples \u2014 para perguntas diretas"}),"\n",(0,s.jsx)(n.p,{children:"Use quando voc\xea tem uma pergunta \xfanica, sem necessidade de contexto anterior:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'response = client.responses.create(\n    model="sabia-4",\n    input="Qual \xe9 a capital do Brasil?",\n)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"lista-de-mensagens--para-conversas-e-contexto",children:"Lista de mensagens \u2014 para conversas e contexto"}),"\n",(0,s.jsx)(n.p,{children:"Use quando precisa manter o hist\xf3rico da conversa ou definir pap\xe9is (usu\xe1rio, assistente):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'response = client.responses.create(\n    model="sabia-4",\n    input=[\n        {"role": "user", "content": "Meu nome \xe9 Alice."},\n        {"role": "assistant", "content": "Ol\xe1 Alice! Prazer em conhec\xea-la."},\n        {"role": "user", "content": "Qual \xe9 o meu nome?"},\n    ],\n)\n\nprint(response.output[0].content[0].text)  # Deve mencionar "Alice"\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Pap\xe9is suportados: ",(0,s.jsx)(n.code,{children:"user"})," (usu\xe1rio), ",(0,s.jsx)(n.code,{children:"assistant"})," (modelo), ",(0,s.jsx)(n.code,{children:"system"})," (instru\xe7\xf5es de sistema) e ",(0,s.jsx)(n.code,{children:"developer"})," (instru\xe7\xf5es de desenvolvedor)."]}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)("div",{className:"custom-box",style:{display:"flex",alignItems:"center",backgroundColor:"var(--ifm-table-stripe-background)",padding:"12px",border:"1px solid var(--navbar-border)",borderRadius:"8px",margin:"12px 0",color:"var(--ifm-font-color-base)"},children:(0,s.jsxs)("div",{children:[(0,s.jsxs)("strong",{style:{display:"block",fontSize:"1em",marginBottom:"5px"},children:["Dica: Use ",(0,s.jsx)(n.code,{children:"instructions"})," para definir o comportamento"]}),(0,s.jsxs)("p",{style:{fontSize:"0.9em"},children:["Em vez de incluir instru\xe7\xf5es de sistema na lista de mensagens, voc\xea pode usar o par\xe2metro ",(0,s.jsx)("code",{children:"instructions"}),". Isso separa o comportamento do modelo do conte\xfado da conversa, tornando o c\xf3digo mais limpo e organizado."]})]})}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(n.h3,{id:"com-instru\xe7\xf5es-de-sistema",children:"Com instru\xe7\xf5es de sistema"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'response = client.responses.create(\n    model="sabia-4",\n    instructions="Voc\xea \xe9 um professor de hist\xf3ria. Responda de forma did\xe1tica.",\n    input="Quem foi Dom Pedro I?",\n)\n\nprint(response.output[0].content[0].text)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"streaming-resposta-em-tempo-real",children:"Streaming (resposta em tempo real)"}),"\n",(0,s.jsxs)(n.p,{children:["Por padr\xe3o, a API aguarda o modelo gerar toda a resposta antes de retorn\xe1-la. Com streaming, voc\xea recebe a resposta ",(0,s.jsx)(n.strong,{children:"palavra por palavra"}),", conforme \xe9 gerada \u2014 ideal para interfaces de chat ou respostas longas."]}),"\n",(0,s.jsxs)(o.A,{children:[(0,s.jsx)(r.A,{value:"python",label:"Python",default:!0,children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'stream = client.responses.create(\n    model="sabia-4",\n    input="Conte uma breve hist\xf3ria sobre o Brasil.",\n    stream=True,\n)\n\nfor event in stream:\n    if event.type == "response.output_text.delta":\n        print(event.delta, end="", flush=True)\n'})})}),(0,s.jsx)(r.A,{value:"curl",label:"cURL",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST https://chat.maritaca.ai/api/v1/responses \\\n  -H "Authorization: Bearer SUA_CHAVE_API" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "sabia-4",\n    "input": "Conte uma breve hist\xf3ria sobre o Brasil.",\n    "stream": true\n  }\'\n'})})})]}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)("div",{className:"custom-box",style:{display:"flex",alignItems:"center",backgroundColor:"var(--ifm-table-stripe-background)",padding:"12px",border:"1px solid var(--navbar-border)",borderRadius:"8px",margin:"12px 0",color:"var(--ifm-font-color-base)"},children:(0,s.jsxs)("div",{children:[(0,s.jsx)("strong",{style:{display:"block",fontSize:"1em",marginBottom:"5px"},children:"Na pr\xe1tica"}),(0,s.jsxs)("p",{style:{fontSize:"0.9em"},children:["O evento principal \xe9 o ",(0,s.jsx)("code",{children:"response.output_text.delta"}),", que cont\xe9m cada fragmento de texto gerado. Os demais eventos (",(0,s.jsx)("code",{children:"response.created"}),", ",(0,s.jsx)("code",{children:"response.completed"}),", etc.) s\xe3o \xfateis para controle avan\xe7ado, como saber quando a resposta terminou ou rastrear uso de tokens. Em caso de erro, um evento ",(0,s.jsx)(n.code,{children:"response.failed"})," \xe9 emitido no lugar de ",(0,s.jsx)(n.code,{children:"response.completed"}),"."]})]})}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(n.h2,{id:"mais-exemplos",children:"Mais exemplos"}),"\n",(0,s.jsx)(n.h3,{id:"exemplo-1--chamada-de-fun\xe7\xf5es-fluxo-completo",children:"Exemplo 1 \u2014 Chamada de fun\xe7\xf5es (fluxo completo)"}),"\n",(0,s.jsxs)(n.p,{children:["O fluxo inteiro de function calling com uma API real: definir a tool, enviar a pergunta, receber o ",(0,s.jsx)(n.code,{children:"function_call"}),", executar a fun\xe7\xe3o localmente chamando a ",(0,s.jsx)(n.a,{href:"https://open-meteo.com/",children:"API Open-Meteo"})," e devolver o resultado ao modelo para obter a resposta final."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import openai\nimport requests\nimport json\n\nclient = openai.OpenAI(\n    api_key="SUA_CHAVE_API",\n    base_url="https://chat.maritaca.ai/api",\n)\n\n# Definir a fun\xe7\xe3o que ser\xe1 executada\ndef consultar_previsao_tempo(latitude, longitude):\n    """Consulta a API Open-Meteo e retorna dados reais."""\n    response = requests.get(\n        "https://api.open-meteo.com/v1/forecast",\n        params={\n            "latitude": latitude,\n            "longitude": longitude,\n            "current_weather": True,\n            "timezone": "America/Sao_Paulo",\n        },\n    )\n    dados = response.json()\n    return {\n        "temperatura": dados["current_weather"]["temperature"],\n        "unidade": "\xb0C",\n    }\n\ntools = [\n    {\n        "type": "function",\n        "name": "consultar_previsao_tempo",\n        "description": "Obt\xe9m a previs\xe3o do tempo atual para uma localiza\xe7\xe3o.",\n        "parameters": {\n            "type": "object",\n            "properties": {\n                "latitude": {\n                    "type": "number",\n                    "description": "Latitude da cidade.",\n                },\n                "longitude": {\n                    "type": "number",\n                    "description": "Longitude da cidade.",\n                },\n            },\n            "required": ["latitude", "longitude"],\n        },\n    }\n]\n\nresponse = client.responses.create(\n    model="sabia-4",\n    input="Qual \xe9 a previs\xe3o do tempo no Rio de Janeiro?",\n    tools=tools,\n)\n\n# Verificar que o modelo pediu uma chamada de fun\xe7\xe3o\ntool_call = response.output[0]\nassert tool_call.type == "function_call"\n\nprint(f"Fun\xe7\xe3o: {tool_call.name}")         # "consultar_previsao_tempo"\nprint(f"Argumentos: {tool_call.arguments}") # \'{"latitude": -22.9068, "longitude": -43.1729}\'\nprint(f"call_id: {tool_call.call_id}")      # "call_abc123..."\n\n# Executar a fun\xe7\xe3o com os argumentos do modelo\nargs = json.loads(tool_call.arguments)\nresultado_real = consultar_previsao_tempo(args["latitude"], args["longitude"])\nprint(f"Dados reais da API: {resultado_real}")\n# {"temperatura": 25.6, "unidade": "\xb0C"}\n\n# Devolver o resultado ao modelo para ele formular a resposta final\nfinal_response = client.responses.create(\n    model="sabia-4",\n    input=[\n        {"role": "user", "content": "Qual \xe9 a previs\xe3o do tempo no Rio de Janeiro?"},\n        {\n            "type": "function_call",\n            "call_id": tool_call.call_id,\n            "name": tool_call.name,\n            "arguments": tool_call.arguments,\n        },\n        {\n            "type": "function_call_output",\n            "call_id": tool_call.call_id,\n            "output": json.dumps(resultado_real),\n        },\n    ],\n    tools=tools,\n)\n\nprint(final_response.output[0].content[0].text)\n# "A previs\xe3o do tempo no Rio de Janeiro indica uma temperatura atual de 24,8\u202f\xb0C."\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exemplo-2--sa\xeddas-estruturadas-com-pydantic",children:"Exemplo 2 \u2014 Sa\xeddas estruturadas com Pydantic"}),"\n",(0,s.jsxs)(n.p,{children:["Use Pydantic para definir o schema, passe-o via ",(0,s.jsx)(n.code,{children:"text.format"})," e valide o resultado automaticamente."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import openai\nimport json\nfrom pydantic import BaseModel\nfrom typing import List\n\nclient = openai.OpenAI(\n    api_key="SUA_CHAVE_API",\n    base_url="https://chat.maritaca.ai/api",\n)\n\n# 1. Definir o schema com Pydantic\nclass Event(BaseModel):\n    name: str\n    date: str\n    location: str\n\nclass ExtractedEvents(BaseModel):\n    events: List[Event]\n\n# 2. Enviar com formato estruturado\nresponse = client.responses.create(\n    model="sabia-4",\n    instructions="Extraia os eventos mencionados no texto.",\n    input="A Copa do Mundo de 2014 foi realizada no Brasil. "\n          "As Olimp\xedadas de 2016 aconteceram no Rio de Janeiro.",\n    text={\n        "format": {\n            "type": "json_schema",\n            "name": "extracted_events",\n            "schema": ExtractedEvents.model_json_schema(),\n            "strict": True,\n        }\n    },\n)\n\n# 3. Parsear e validar o resultado\nraw_json = response.output[0].content[0].text\ndata = json.loads(raw_json)\nresult = ExtractedEvents.model_validate(data)\n\nfor event in result.events:\n    print(f"{event.name} \u2014 {event.date} em {event.location}")\n# "Copa do Mundo \u2014 2014 em Brasil"\n# "Olimp\xedadas \u2014 2016 em Rio de Janeiro"\n'})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["Para mais op\xe7\xf5es de formato (",(0,s.jsx)(n.code,{children:"json_object"}),", ",(0,s.jsx)(n.code,{children:"strict"}),"), veja ",(0,s.jsx)(n.a,{href:"/pt/structured-outputs",children:"Sa\xeddas Estruturadas"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"exemplo-3--streaming-com-tracking-de-tokens",children:"Exemplo 3 \u2014 Streaming com tracking de tokens"}),"\n",(0,s.jsx)(n.p,{children:"Acumule o texto gerado e capture as estat\xedsticas de uso de tokens ao final do stream."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import openai\n\nclient = openai.OpenAI(\n    api_key="SUA_CHAVE_API",\n    base_url="https://chat.maritaca.ai/api",\n)\n\nstream = client.responses.create(\n    model="sabia-4",\n    input="Explique a import\xe2ncia da Floresta Amaz\xf4nica em 3 par\xe1grafos.",\n    stream=True,\n)\n\nfull_text = ""\nusage = None\n\nfor event in stream:\n    if event.type == "response.output_text.delta":\n        # Acumular o texto gerado\n        full_text += event.delta\n        print(event.delta, end="", flush=True)\n\n    elif event.type == "response.completed":\n        # Capturar estat\xedsticas de tokens\n        usage = event.response.usage\n\nprint("\\n")\nprint(f"--- Estat\xedsticas ---")\nprint(f"Tokens de entrada:  {usage.input_tokens}")\nprint(f"Tokens de sa\xedda:    {usage.output_tokens}")\nprint(f"Total de tokens:    {usage.total_tokens}")\nprint(f"Tamanho do texto:   {len(full_text)} caracteres")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"exemplo-4--chatbot-multi-turno-com-mem\xf3ria",children:"Exemplo 4 \u2014 Chatbot multi-turno com mem\xf3ria"}),"\n",(0,s.jsxs)(n.p,{children:["Um loop de conversa onde o hist\xf3rico \xe9 mantido na lista de ",(0,s.jsx)(n.code,{children:"input"}),", permitindo que o modelo lembre de mensagens anteriores."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import openai\n\nclient = openai.OpenAI(\n    api_key="SUA_CHAVE_API",\n    base_url="https://chat.maritaca.ai/api",\n)\n\nhistory = []\n\nprint("Chatbot (digite \'sair\' para encerrar)")\nprint("-" * 40)\n\nwhile True:\n    user_input = input("Voc\xea: ")\n    if user_input.lower() == "sair":\n        break\n\n    history.append({"role": "user", "content": user_input})\n\n    response = client.responses.create(\n        model="sabia-4",\n        instructions="Voc\xea \xe9 um assistente simp\xe1tico e prestativo.",\n        input=history,\n    )\n\n    assistant_message = response.output[0].content[0].text\n    history.append({"role": "assistant", "content": assistant_message})\n\n    print(f"Assistente: {assistant_message}")\n'})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"O hist\xf3rico cresce a cada turno. Para conversas longas, considere limitar o n\xfamero de mensagens ou usar resumos para manter o consumo de tokens sob controle."}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},9365:(e,n,a)=>{a.d(n,{A:()=>r});a(6540);var s=a(4164);const t={tabItem:"tabItem_Ymn6"};var o=a(4848);function r(e){let{children:n,hidden:a,className:r}=e;return(0,o.jsx)("div",{role:"tabpanel",className:(0,s.A)(t.tabItem,r),hidden:a,children:n})}},1470:(e,n,a)=>{a.d(n,{A:()=>A});var s=a(6540),t=a(4164),o=a(3104),r=a(6347),i=a(205),l=a(7485),c=a(1682),d=a(679);function u(e){return s.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,s.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:n,children:a}=e;return(0,s.useMemo)((()=>{const e=n??function(e){return u(e).map((e=>{let{props:{value:n,label:a,attributes:s,default:t}}=e;return{value:n,label:a,attributes:s,default:t}}))}(a);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,a])}function m(e){let{value:n,tabValues:a}=e;return a.some((e=>e.value===n))}function h(e){let{queryString:n=!1,groupId:a}=e;const t=(0,r.W6)(),o=function(e){let{queryString:n=!1,groupId:a}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:n,groupId:a});return[(0,l.aZ)(o),(0,s.useCallback)((e=>{if(!o)return;const n=new URLSearchParams(t.location.search);n.set(o,e),t.replace({...t.location,search:n.toString()})}),[o,t])]}function x(e){const{defaultValue:n,queryString:a=!1,groupId:t}=e,o=p(e),[r,l]=(0,s.useState)((()=>function(e){let{defaultValue:n,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!m({value:n,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const s=a.find((e=>e.default))??a[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:n,tabValues:o}))),[c,u]=h({queryString:a,groupId:t}),[x,j]=function(e){let{groupId:n}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(n),[t,o]=(0,d.Dv)(a);return[t,(0,s.useCallback)((e=>{a&&o.set(e)}),[a,o])]}({groupId:t}),f=(()=>{const e=c??x;return m({value:e,tabValues:o})?e:null})();(0,i.A)((()=>{f&&l(f)}),[f]);return{selectedValue:r,selectValue:(0,s.useCallback)((e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),j(e)}),[u,j,o]),tabValues:o}}var j=a(2303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=a(4848);function g(e){let{className:n,block:a,selectedValue:s,selectValue:r,tabValues:i}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,o.a_)(),d=e=>{const n=e.currentTarget,a=l.indexOf(n),t=i[a].value;t!==s&&(c(n),r(t))},u=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const a=l.indexOf(e.currentTarget)+1;n=l[a]??l[0];break}case"ArrowLeft":{const a=l.indexOf(e.currentTarget)-1;n=l[a]??l[l.length-1];break}}n?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.A)("tabs",{"tabs--block":a},n),children:i.map((e=>{let{value:n,label:a,attributes:o}=e;return(0,v.jsx)("li",{role:"tab",tabIndex:s===n?0:-1,"aria-selected":s===n,ref:e=>l.push(e),onKeyDown:u,onClick:d,...o,className:(0,t.A)("tabs__item",f.tabItem,o?.className,{"tabs__item--active":s===n}),children:a??n},n)}))})}function b(e){let{lazy:n,children:a,selectedValue:o}=e;const r=(Array.isArray(a)?a:[a]).filter(Boolean);if(n){const e=r.find((e=>e.props.value===o));return e?(0,s.cloneElement)(e,{className:(0,t.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:r.map(((e,n)=>(0,s.cloneElement)(e,{key:n,hidden:e.props.value!==o})))})}function _(e){const n=x(e);return(0,v.jsxs)("div",{className:(0,t.A)("tabs-container",f.tabList),children:[(0,v.jsx)(g,{...n,...e}),(0,v.jsx)(b,{...n,...e})]})}function A(e){const n=(0,j.A)();return(0,v.jsx)(_,{...e,children:u(e.children)},String(n))}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>i});var s=a(6540);const t={},o=s.createContext(t);function r(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);