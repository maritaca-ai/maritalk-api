"use strict";(self.webpackChunkmaritaca=self.webpackChunkmaritaca||[]).push([[338],{9379:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>i,default:()=>l,frontMatter:()=>s,metadata:()=>t,toc:()=>c});var o=n(4848),r=n(8453);const s={id:"Sabia-3+RAG",title:"Sabia-3+RAG"},i="RAG com o Sabi\xe1-3",t={id:"pt/Sabia-3+RAG",title:"Sabia-3+RAG",description:"RAG (Retrieval-Augmented Generation) \xe9 uma abordagem que combina busca de informa\xe7\xf5es em uma base de dados com a capacidade de gera\xe7\xe3o de texto de um modelo de linguagem (LLM). Abaixo est\xe1 o passo a passo detalhado para criar um sistema RAG usando o modelo Sabi\xe1-3, neste exemplo utilizaremos:",source:"@site/docs/pt/Sabia-3+RAG.md",sourceDirName:"pt",slug:"/pt/Sabia-3+RAG",permalink:"/en/pt/Sabia-3+RAG",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"Sabia-3+RAG",title:"Sabia-3+RAG"},sidebar:"sidebarPt",previous:{title:"Chamada de fun\xe7\xf5es",permalink:"/en/pt/chamada-funcao"},next:{title:"Embeddings",permalink:"/en/pt/embeddings"}},d={},c=[{value:"Passo 1: Instalar as Depend\xeancias",id:"passo-1-instalar-as-depend\xeancias",level:2},{value:"Passo 2: Baixe o PDF",id:"passo-2-baixe-o-pdf",level:2},{value:"Passo 3: Carregar e processar o documento",id:"passo-3-carregar-e-processar-o-documento",level:2},{value:"Passo 4: Configurar o Sabi\xe1-3",id:"passo-4-configurar-o-sabi\xe1-3",level:2},{value:"Passo 5: Definir o prompt",id:"passo-5-definir-o-prompt",level:2},{value:"Passo 6: Criar cadeia de Pergunta Resposta",id:"passo-6-criar-cadeia-de-pergunta-resposta",level:2},{value:"Passo 7: Executar a consulta",id:"passo-7-executar-a-consulta",level:2}];function p(e){const a={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(a.header,{children:(0,o.jsx)(a.h1,{id:"rag-com-o-sabi\xe1-3",children:"RAG com o Sabi\xe1-3"})}),"\n",(0,o.jsx)(a.p,{children:"RAG (Retrieval-Augmented Generation) \xe9 uma abordagem que combina busca de informa\xe7\xf5es em uma base de dados com a capacidade de gera\xe7\xe3o de texto de um modelo de linguagem (LLM). Abaixo est\xe1 o passo a passo detalhado para criar um sistema RAG usando o modelo Sabi\xe1-3, neste exemplo utilizaremos:"}),"\n",(0,o.jsxs)(a.ul,{children:["\n",(0,o.jsx)(a.li,{children:"Uma fonte de dados (um PDF de um edital da Unicamp)."}),"\n",(0,o.jsx)(a.li,{children:"Uma ferramenta para extrair e dividir o texto do PDF em peda\xe7os (chunks)."}),"\n",(0,o.jsx)(a.li,{children:"Um sistema de recupera\xe7\xe3o (retriever) baseado em BM25, que busca os trechos mais relevantes para uma determinada pergunta."}),"\n",(0,o.jsx)(a.li,{children:"O modelo Sabi\xe1-3 para gerar a resposta final."}),"\n",(0,o.jsx)(a.li,{children:"O prompt baseado no formato de conversa, fornecendo contexto e a pergunta do usu\xe1rio."}),"\n"]}),"\n",(0,o.jsx)(a.h2,{id:"passo-1-instalar-as-depend\xeancias",children:"Passo 1: Instalar as Depend\xeancias"}),"\n",(0,o.jsx)(a.p,{children:"Primeiro, instale as bibliotecas necess\xe1rias para o projeto."}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-bash",children:'!pip install unstructured rank_bm25 pdf2image pdfminer-six pikepdf pypdf unstructured_inference "pillow<10.1.0" pillow_heif -q\n!pip install langchain langchain-community langchain_openai -q\n'})}),"\n",(0,o.jsx)(a.h2,{id:"passo-2-baixe-o-pdf",children:"Passo 2: Baixe o PDF"}),"\n",(0,o.jsx)(a.p,{children:"No exemplo, utilizamos um edital da Unicamp. Para baix\xe1-lo localmente:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-bash",children:"!wget https://www.comvest.unicamp.br/wp-content/uploads/2023/10/31-2023-Dispoe-sobre-o-Vestibular-Unicamp-2024_com-retificacao.pdf -O edital_unicamp_2024.pdf\n"})}),"\n",(0,o.jsx)(a.h2,{id:"passo-3-carregar-e-processar-o-documento",children:"Passo 3: Carregar e processar o documento"}),"\n",(0,o.jsx)(a.p,{children:"Utilizaremos o PyPDFLoader do LangChain para extrair o texto, e depois faremos o split do texto em chunks menores usando RecursiveCharacterTextSplitter."}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'from langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Carregar o PDF\nloader = PyPDFLoader("edital_unicamp_2024.pdf")\ndata = loader.load()\n\n# Dividir o texto em chunks\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=500,\n    chunk_overlap=100,\n    separators=["\\n", " ", ""]\n)\ntexts = text_splitter.split_documents(data)\n\n'})}),"\n",(0,o.jsx)(a.p,{children:"Com o texto em chunks, criamos um retriever usando BM25Retriever para encontrar os trechos mais relevantes:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:"from langchain_community.retrievers import BM25Retriever\n\nretriever = BM25Retriever.from_documents(texts)\n"})}),"\n",(0,o.jsx)(a.h2,{id:"passo-4-configurar-o-sabi\xe1-3",children:"Passo 4: Configurar o Sabi\xe1-3"}),"\n",(0,o.jsx)(a.p,{children:"Aqui, utilizamos a compatibilidade com a OpenAI atrav\xe9s do ChatOpenAI para acessar o modelo Sabi\xe1-3. \xc9 necess\xe1rio fornecer a base_url e a api_key."}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'from langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI(\n    model="sabia-3",\n    temperature=0,\n    api_key=api_key, # Insira sua chave aqui  \n    base_url="https://chat.maritaca.ai/api",\n)\n\n'})}),"\n",(0,o.jsx)(a.h2,{id:"passo-5-definir-o-prompt",children:"Passo 5: Definir o prompt"}),"\n",(0,o.jsx)(a.p,{children:"Vamos criar um prompt simples que fornecer\xe1 o contexto (documentos recuperados) e a pergunta do usu\xe1rio."}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'from langchain.prompts import PromptTemplate\n\nprompt = PromptTemplate(\n    input_variables=["context", "query"],\n    template="Baseado nos seguintes documentos, responda a pergunta abaixo.\\n\\n{context}\\n\\nPergunta: {query}"\n)\n'})}),"\n",(0,o.jsx)(a.h2,{id:"passo-6-criar-cadeia-de-pergunta-resposta",children:"Passo 6: Criar cadeia de Pergunta Resposta"}),"\n",(0,o.jsx)(a.p,{children:"Agora criamos a cadeia de QA utilizando o load_qa_chain do LangChain."}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'from langchain.chains.question_answering import load_qa_chain\n\nchain = load_qa_chain(llm, chain_type="stuff", prompt=prompt, verbose=True)\n'})}),"\n",(0,o.jsx)(a.h2,{id:"passo-7-executar-a-consulta",children:"Passo 7: Executar a consulta"}),"\n",(0,o.jsx)(a.p,{children:"Finalmente, vamos fazer uma pergunta ao sistema. Primeiro, recuperamos os documentos relevantes com o retriever, depois passamos tudo para a cadeia."}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'query = "Qual o tempo m\xe1ximo para realiza\xe7\xe3o da prova?"\ndocs = retriever.invoke(query)\n\ntry:\n    answer = chain({"input_documents": docs, "query": query})\n    print(answer)\nexcept Exception as e:\n    print(f"Erro durante execu\xe7\xe3o: {e}")\n\n'})}),"\n",(0,o.jsx)(a.p,{children:"A consulta feita ao sistema retornar\xe1 um resultado no formato JSON, estruturado da seguinte forma:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-json",children:'{\n  "input_documents": [\n    {\n      "metadata": {\n        "source": "edital_unicamp_2024.pdf",\n        "page": 8\n      },\n      "page_content": "M\xe9dio, incluindo quest\xf5es interdisciplinares. \\n\\n\xa71\xba O(a) candidato(a) ter\xe1 no m\xe1ximo 5 (cinco) horas e no m\xednimo 2 duas horas para a \\nrealiza\xe7\xe3o da prova da 1\xaa fase. Poder\xe1 ser concedido tempo adicional aos(\xe0s) candidatos(as) nos \\ncasos previstos no art. 14."\n    },\n    {\n      "metadata": {\n        "source": "edital_unicamp_2024.pdf",\n        "page": 78\n      },\n      "page_content": "c. Com maior tempo para a realiza\xe7\xe3o da prova, tempo este estabelecido de acordo com \\ncrit\xe9rios neuropsicol\xf3gicos, at\xe9 o limite de 20% do tempo regular."\n    }\n    // ... outros documentos\n  ],\n  "query": "Qual o tempo m\xe1ximo para realiza\xe7\xe3o da prova?",\n  "output_text": "O tempo m\xe1ximo para a realiza\xe7\xe3o da prova \xe9 de 5 (cinco) horas."\n}\n\n'})})]})}function l(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,o.jsx)(a,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>i,x:()=>t});var o=n(6540);const r={},s=o.createContext(r);function i(e){const a=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function t(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:a},e.children)}}}]);